{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://www.kaggle.com/code/ahmedwael2000/pytorch?scriptVersionId=139142743\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename)\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-07T04:44:44.257879Z","iopub.status.busy":"2023-08-07T04:44:44.257533Z","iopub.status.idle":"2023-08-07T04:44:54.524921Z","shell.execute_reply":"2023-08-07T04:44:54.523812Z","shell.execute_reply.started":"2023-08-07T04:44:44.257852Z"},"trusted":true},"outputs":[],"source":["!pip install torchsummary"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-08-07T04:44:54.528614Z","iopub.status.busy":"2023-08-07T04:44:54.528251Z","iopub.status.idle":"2023-08-07T04:44:54.536852Z","shell.execute_reply":"2023-08-07T04:44:54.53589Z","shell.execute_reply.started":"2023-08-07T04:44:54.528579Z"},"trusted":true},"outputs":[],"source":["import os \n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision\n","import torchvision.transforms as T\n","from torchvision import models\n","from torchsummary import summary\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T19:46:20.699288Z","iopub.status.busy":"2023-08-06T19:46:20.697628Z","iopub.status.idle":"2023-08-06T19:46:20.747507Z","shell.execute_reply":"2023-08-06T19:46:20.746297Z","shell.execute_reply.started":"2023-08-06T19:46:20.699214Z"},"trusted":true},"outputs":[],"source":["data_path = '/kaggle/input/butterfly-image-classification'\n","\n","test_path = os.path.join(data_path, 'test')\n","train_path = os.path.join(data_path, 'train')\n","\n","df = pd.read_csv(os.path.join(data_path, 'Training_set.csv'))\n","test_df = pd.read_csv(os.path.join(data_path, 'Testing_set.csv'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T19:46:21.220612Z","iopub.status.busy":"2023-08-06T19:46:21.219882Z","iopub.status.idle":"2023-08-06T19:46:21.258772Z","shell.execute_reply":"2023-08-06T19:46:21.257397Z","shell.execute_reply.started":"2023-08-06T19:46:21.220576Z"},"trusted":true},"outputs":[],"source":["# converting type of columns to 'category'\n","df['label'] = df['label'].astype('category')\n","\n","# Assigning numerical values and storing in another column\n","df['encoded_label'] = df['label'].cat.codes\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Splitting the dataframe into 2 dataframes\n","train_df, cv_df = train_test_split(df, test_size=0.15)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T19:46:47.954107Z","iopub.status.busy":"2023-08-06T19:46:47.953715Z","iopub.status.idle":"2023-08-06T19:46:47.964361Z","shell.execute_reply":"2023-08-06T19:46:47.962899Z","shell.execute_reply.started":"2023-08-06T19:46:47.954077Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, csv_file, data_path, transforms=None):\n","        self.annotations = csv_file\n","        self.data_path = data_path\n","        self.transforms = transforms if transforms else T.ToTensor()\n","        self.num_classes = len(self.annotations.label.unique())\n","        \n","    def __getitem__(self, i):\n","        image_path = os.path.join(self.data_path, self.annotations.iloc[i, 0])\n","        image = self.transforms(Image.open(image_path))\n","\n","        label = F.one_hot(torch.tensor(self.annotations.iloc[i, 2], dtype=int), num_classes=self.num_classes)\n","        label = label.type(torch.float)\n","        \n","        return (image, label)\n","    \n","    def __len__(self):\n","        return len(self.annotations)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["transform_img = T.Compose([\n","    T.Resize(224),\n","    T.CenterCrop(224),\n","    T.ToTensor(),\n","])\n","\n","train_dataset = CustomDataset(train_df, train_path, transform_img)\n","loader = DataLoader(train_dataset, batch_size=16)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# calculating the mean and std of images for normalization\n","def batch_mean_and_sd(loader):\n","    cnt = 0\n","    fst_moment = torch.empty(3)\n","    snd_moment = torch.empty(3)\n","\n","    for images, _ in loader:\n","        b, c, h, w = images.shape\n","        nb_pixels = b * h * w\n","        sum_ = torch.sum(images, dim=[0, 2, 3])\n","        sum_of_square = torch.sum(images ** 2,\n","                                  dim=[0, 2, 3])\n","        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n","        snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n","        cnt += nb_pixels\n","\n","    mean, std = fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)        \n","    return mean, std\n","\n","mean, std = batch_mean_and_sd(loader)\n","print(\"mean and std: \\n\", mean, std)\n","\n","# Or we can set them manually as:\n","# mean = (0.485, 0.456, 0.406)\n","# std = (0.229, 0.224, 0.225)\n","# These values are copied from Imagenet dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T19:46:50.071603Z","iopub.status.busy":"2023-08-06T19:46:50.070724Z","iopub.status.idle":"2023-08-06T19:46:50.10868Z","shell.execute_reply":"2023-08-06T19:46:50.107698Z","shell.execute_reply.started":"2023-08-06T19:46:50.071559Z"},"trusted":true},"outputs":[],"source":["# Applying augmentation and preprocessing to the dataset\n","augment = T.Compose([\n","    T.RandomHorizontalFlip(p=0.5),\n","    T.RandomApply([\n","        T.RandomChoice([\n","            T.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 3.0)),\n","            T.ElasticTransform(alpha=100.0),\n","            T.RandomAdjustSharpness(sharpness_factor=3.0)\n","        ], p=[0.4, 0.3, 0.3]),\n","        T.ColorJitter(brightness=.3, hue=.1, contrast=.2, saturation=0.2),\n","    ], p=0.8),\n","    T.RandomGrayscale(p=0.05),\n","    T.RandomVerticalFlip(p=0.05),\n","    T.RandomRotation(degrees=(-30.0, 30.0)),\n","    T.ToTensor(),\n","    T.Normalize(mean=mean, std=std)\n","])\n","\n","train_dataset = CustomDataset(train_df, train_path, augment)\n","cv_dataset = CustomDataset(cv_df, train_path, augment)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T19:46:51.777679Z","iopub.status.busy":"2023-08-06T19:46:51.777214Z","iopub.status.idle":"2023-08-06T19:46:51.784816Z","shell.execute_reply":"2023-08-06T19:46:51.783525Z","shell.execute_reply.started":"2023-08-06T19:46:51.777641Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Data Loader\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","cv_loader = DataLoader(cv_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["# models  \n","\n","- VGG19 \n","- ResNet18\n","- GoogLeNet (InceptionNet)\n","- MobileNet\n","- EfficientNet"]},{"cell_type":"markdown","metadata":{},"source":["## VGG19"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T06:28:11.733842Z","iopub.status.busy":"2023-08-06T06:28:11.733455Z","iopub.status.idle":"2023-08-06T06:28:27.66637Z","shell.execute_reply":"2023-08-06T06:28:27.665447Z","shell.execute_reply.started":"2023-08-06T06:28:11.733808Z"},"trusted":true},"outputs":[],"source":["class VGG19(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super(VGG19, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(in_channels, 64, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 64, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, stride=2),\n","\n","            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, stride=2),\n","\n","            nn.Conv2d(128, 256, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, stride=2),\n","\n","            nn.Conv2d(256, 512, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, stride=2),\n","\n","            nn.Conv2d(512, 512, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, 3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, stride=2),\n","\n","            nn.Flatten(),\n","            nn.Linear(in_features=25088, out_features=4096),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(in_features=4096, out_features=4096),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(in_features=4096, out_features=num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","vgg19 = VGG19(3, 1000).to(device)\n","summary(vgg19, (3, 224, 224))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T06:30:06.65143Z","iopub.status.busy":"2023-08-06T06:30:06.651079Z","iopub.status.idle":"2023-08-06T06:30:08.615587Z","shell.execute_reply":"2023-08-06T06:30:08.614534Z","shell.execute_reply.started":"2023-08-06T06:30:06.651402Z"},"trusted":true},"outputs":[],"source":["# Load the pretrained VGG19 model\n","pretrained_vgg19 = models.vgg19(pretrained=True).to(device)\n","summary(pretrained_vgg19, (3, 224, 224))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T06:30:08.618145Z","iopub.status.busy":"2023-08-06T06:30:08.617603Z","iopub.status.idle":"2023-08-06T06:30:08.644961Z","shell.execute_reply":"2023-08-06T06:30:08.643948Z","shell.execute_reply.started":"2023-08-06T06:30:08.618108Z"},"trusted":true},"outputs":[],"source":["# Loop over the layers of the model\n","for name, layer in list(pretrained_vgg19.named_children()):\n","    # We can freeze all these layers as they are already pre-trained\n","    print(name) # just displaying the name of each layer\n","\n","# We need to classify 75 classes!!\n","num_classes = 75\n","\n","# Delete the last layer (classifier)\n","pretrained_vgg19 = nn.Sequential(\n","    *list(pretrained_vgg19.children())[:-1],\n","    nn.Flatten(),\n","    *list(pretrained_vgg19.children())[-1][:-1],\n",").to(device)\n","\n","# Insert a custom linear layer at the end for predicting 75 classes\n","custom_linear_layer = nn.Linear(in_features=4096, out_features=num_classes).to(device)\n","\n","pretrained_vgg19.add_module('custom_linear', custom_linear_layer)\n","summary(pretrained_vgg19, (3, 224, 224))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T06:30:23.047327Z","iopub.status.busy":"2023-08-06T06:30:23.046956Z","iopub.status.idle":"2023-08-06T06:30:23.053127Z","shell.execute_reply":"2023-08-06T06:30:23.051909Z","shell.execute_reply.started":"2023-08-06T06:30:23.047296Z"},"trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(pretrained_vgg19.parameters(), lr=1e-4)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T06:31:10.22634Z","iopub.status.busy":"2023-08-06T06:31:10.225958Z","iopub.status.idle":"2023-08-06T06:31:10.233431Z","shell.execute_reply":"2023-08-06T06:31:10.232479Z","shell.execute_reply.started":"2023-08-06T06:31:10.226312Z"},"trusted":true},"outputs":[],"source":["def train_model(train_loader, model, criterion, optimizer, device='cpu', epochs=10):\n","    model.train()\n","    for epoch in range(epochs):\n","        for images, target in train_loader:\n","            output = model(images.to(device))\n","            \n","            optimizer.zero_grad()\n","            \n","            loss = criterion(output, target.to(device))\n","            loss.backward()\n","            \n","            optimizer.step()\n","            \n","        if epoch % 5 == 0:\n","            print(f'epoch {epoch}: loss: {loss}')\n","            \n","    print(f'training end, loss: {loss}')\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T06:31:10.494133Z","iopub.status.busy":"2023-08-06T06:31:10.492965Z","iopub.status.idle":"2023-08-06T07:07:42.99133Z","shell.execute_reply":"2023-08-06T07:07:42.990346Z","shell.execute_reply.started":"2023-08-06T06:31:10.494088Z"},"trusted":true},"outputs":[],"source":["new_vgg19 = train_model(train_loader, pretrained_vgg19, criterion, optimizer, device=device, epochs=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T07:10:23.036587Z","iopub.status.busy":"2023-08-06T07:10:23.036216Z","iopub.status.idle":"2023-08-06T07:10:24.109518Z","shell.execute_reply":"2023-08-06T07:10:24.108404Z","shell.execute_reply.started":"2023-08-06T07:10:23.036558Z"},"trusted":true},"outputs":[],"source":["# Saving our trained model\n","torch.save(new_vgg19.state_dict(), 'trained_vgg19.pth')"]},{"cell_type":"markdown","metadata":{},"source":["## ResNet18"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ResBlock(nn.Module):\n","    def __init__(self, in_n, out_n, stride=1):\n","        \n","        super(ResBlock,self).__init__()\n","        self.conv1 = nn.Conv2d(in_n, out_n, 3, padding=1, stride=stride, bias=False)\n","        self.conv2 = nn.Conv2d(out_n, out_n, 3, padding=1, bias=False)\n","        self.relu = nn.ReLU()\n","        self.bn1 = nn.BatchNorm2d(out_n)\n","        self.bn2 = nn.BatchNorm2d(out_n)\n","        \n","        if stride != 1 or in_n != out_n:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_n, out_n, 1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_n)\n","            )\n","        else:\n","            self.shortcut = nn.Identity()\n","        \n","    def forward(self, x):\n","        \n","        res = self.shortcut(x)\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        \n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x += res\n","        \n","        return self.relu(x)\n","        \n","        \n","class ResNet18(nn.Module):\n","    def __init__(self, in_n, num_classes):\n","        super(ResNet18,self).__init__()\n","        self.conv1 = nn.Conv2d(in_n, 64, 7, stride=2, padding=3)\n","        self.pool1 = nn.MaxPool2d(3, stride=2, padding=1)\n","        self.block1 = ResBlock(64, 64)\n","        self.block2 = ResBlock(64, 64)\n","        self.block3 = ResBlock(64, 128, stride=2)\n","        self.block4 = ResBlock(128, 128)\n","        self.block5 = ResBlock(128, 256, stride=2)\n","        self.block6 = ResBlock(256, 256)        \n","        self.block7 = ResBlock(256, 512, stride=2)\n","        self.block8 = ResBlock(512, 512)\n","        self.avgpool = nn.AvgPool2d(7)\n","        self.fc = nn.Linear(512, num_classes)\n","        \n","    def forward(self, x):\n","        return nn.Sequential(\n","                    self.conv1,\n","                    self.pool1,\n","                    self.block1,\n","                    self.block2,\n","                    self.block3,\n","                    self.block4,\n","                    self.block5,\n","                    self.block6,\n","                    self.block7,\n","                    self.block8,\n","                    self.avgpool,\n","                    nn.Flatten(),\n","                    self.fc,\n","        )(x)\n","\n","resnet18 = ResNet18(3, 1000) \n","summary(resnet18, (3, 224, 224))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load pretrained resnet18\n","pretrained_resnet18 = models.resnet18(pretrained=True)\n","summary(pretrained_resnet18, (3,224,224))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_classes = 75\n","\n","# Insert a custom linear layer at the end for predicting 75 classes\n","pretrained_resnet18.fc = nn.Linear(in_features=pretrained_resnet18.fc.in_features,out_features= num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["optimizer = optim.Adam(pretrained_res.parameters(), lr=1e-4)\n","new_resnet18 = train_model(train_loader, pretrained_resnet18, criterion, optimizer, device=device, epochs=20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Saving our trained model\n","torch.save(new_resnet18.state_dict(), 'trained_resnet18.pth')"]},{"cell_type":"markdown","metadata":{},"source":["## Inception Module (GoogLeNet)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-08-07T05:00:56.296863Z","iopub.status.busy":"2023-08-07T05:00:56.296436Z","iopub.status.idle":"2023-08-07T05:00:56.318885Z","shell.execute_reply":"2023-08-07T05:00:56.31695Z","shell.execute_reply.started":"2023-08-07T05:00:56.296838Z"},"trusted":true},"outputs":[],"source":["class Conv_block(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, padding=0, stride=1):\n","        super(Conv_block, self).__init__()\n","\n","        self.conv_block = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU()\n","        )\n","\n","    def forward(self, x):\n","        return self.conv_block(x)\n","\n","class Inception_block(nn.Module):\n","    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, pool_1x1):\n","        super(Inception_block, self).__init__()\n","        self.branch1 = Conv_block(in_channels, out_1x1, kernel_size=1)\n","        \n","        self.branch2 = nn.Sequential(\n","            Conv_block(in_channels, red_3x3, kernel_size=1),\n","            Conv_block(red_3x3, out_3x3, kernel_size=3, padding=1)\n","        )\n","        \n","        self.branch3 = nn.Sequential(\n","            Conv_block(in_channels, red_5x5, kernel_size=1),\n","            Conv_block(red_5x5, out_5x5, kernel_size=5, padding=2)\n","        )\n","        \n","        self.branch4 = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n","            Conv_block(in_channels, pool_1x1, kernel_size=1)\n","        )\n","        \n","    def forward(self, x):\n","        branch1 = self.branch1(x)\n","        branch2 = self.branch2(x)\n","        branch3 = self.branch3(x)\n","        branch4 = self.branch4(x)\n","        \n","        return torch.concat([branch1, branch2, branch3, branch4], dim=1) # (batch_size, n_channels, height, width) (1, 3, 224, 224)\n","    \n","\n","class Inception_Net(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super(Inception_Net, self).__init__()\n","        self.model = nn.Sequential(\n","            Conv_block(in_channels, 64, kernel_size=7, stride=2, padding=3), # 7x7 block\n","            nn.MaxPool2d(kernel_size=3, padding=1, stride=2),\n","            \n","            Conv_block(64, 192, kernel_size=3, stride=1, padding=1), # 3x3 block\n","            nn.MaxPool2d(kernel_size=3, padding=1, stride=2),\n","            \n","            # in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, pool_1x1\n","            \n","            Inception_block(192, 64, 96, 128, 16, 32, 32), # inception3a block\n","            Inception_block(256, 128, 128, 192, 32, 96, 64), # inception3b block\n","            \n","            nn.MaxPool2d(kernel_size=3, padding=1, stride=2),\n","            \n","            Inception_block(480, 192, 96, 208, 16, 48, 64), # inception4a block\n","            Inception_block(512, 160, 112, 224, 24, 64, 64), # inception4b block\n","            Inception_block(512, 128, 128, 256, 24, 64, 64), # inception4c block\n","            Inception_block(512, 112, 144, 288, 32, 64, 64), # inception4d block\n","            Inception_block(528, 256, 160, 320, 32, 128, 128), # inception4e block\n","            \n","            nn.MaxPool2d(kernel_size=3, padding=1, stride=2),\n","            \n","            Inception_block(832, 256, 160, 320, 32, 128, 128), # inception5a block\n","            Inception_block(832, 384, 192, 384, 48, 128, 128), # inception5b block\n","            \n","            nn.AdaptiveAvgPool2d((1, 1)),\n","            nn.Dropout(p=0.4),\n","            nn.Flatten(),\n","            nn.Linear(in_features=1024, out_features=num_classes)\n","        )\n","        \n","    def forward(self, x):\n","        return self.model(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-07T05:00:58.345909Z","iopub.status.busy":"2023-08-07T05:00:58.345462Z","iopub.status.idle":"2023-08-07T05:00:58.751291Z","shell.execute_reply":"2023-08-07T05:00:58.746577Z","shell.execute_reply.started":"2023-08-07T05:00:58.345862Z"},"trusted":true},"outputs":[],"source":["Net = Inception_Net(3, 1000)\n","\n","summary(Net, (3, 224, 224))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-07T05:04:18.410556Z","iopub.status.busy":"2023-08-07T05:04:18.40866Z","iopub.status.idle":"2023-08-07T05:04:19.773358Z","shell.execute_reply":"2023-08-07T05:04:19.772252Z","shell.execute_reply.started":"2023-08-07T05:04:18.410492Z"},"trusted":true},"outputs":[],"source":["# Load the pretrained VGG19 model\n","pretrained_inception = models.googlenet(pretrained=True)\n","summary(pretrained_inception, (3, 224, 224))"]},{"cell_type":"markdown","metadata":{},"source":["## MobileNet"]},{"cell_type":"markdown","metadata":{},"source":["### Version 1"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class Depthwise(nn.Module):\n","    def __init__(self, in_channels, kernel_size=3, padding=1, stride=1, bias=True):\n","        super(Depthwise, self).__init__()\n","        \n","        self.depthwise = nn.Conv2d(in_channels, out_channels=in_channels, kernel_size=kernel_size, \n","                                   padding=padding, stride=stride, groups=in_channels, bias=bias)\n","        \n","    def forward(self, x):\n","        return self.depthwise(x)\n","\n","class Mobile_block_v1(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, stride=1):\n","        super(Mobile_block_v1, self).__init__()\n","\n","        self.block = nn.Sequential(\n","            Depthwise(in_channels, kernel_size=kernel_size, \n","                                   padding=padding, stride=stride, bias=False), # Depthwise Convolutional Filters \n","            \n","            nn.BatchNorm2d(in_channels), # Batch Normalization Layer\n","            nn.ReLU(), # applying ReLU activation\n","            \n","            Conv_block(in_channels, out_channels, kernel_size=1,\n","                                    padding=0, stride=1) # Pointwise Convolutional Layer\n","        )\n","        \n","\n","    def forward(self, x):\n","        return self.block(x)\n","        \n","class MobileNet_v1(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super(MobileNet_v1, self).__init__()\n","        \n","        self.net = nn.Sequential(\n","            Conv_block(in_channels, 32, kernel_size=3, padding=1, stride=2),\n","            \n","            Mobile_block_v1(32, 64, kernel_size=3),\n","            Mobile_block_v1(64, 128, kernel_size=3, stride=2),\n","            \n","            Mobile_block_v1(128, 128, kernel_size=3),\n","            Mobile_block_v1(128, 256, kernel_size=3, stride=2),\n","            \n","            Mobile_block_v1(256, 256, kernel_size=3),\n","            Mobile_block_v1(256, 512, kernel_size=3, stride=2),\n","            \n","            Mobile_block_v1(512, 512, kernel_size=3),\n","            Mobile_block_v1(512, 512, kernel_size=3),\n","            Mobile_block_v1(512, 512, kernel_size=3),\n","            Mobile_block_v1(512, 512, kernel_size=3),\n","            Mobile_block_v1(512, 512, kernel_size=3),\n","            \n","            Mobile_block_v1(512, 1024, kernel_size=3, stride=2),\n","            Mobile_block_v1(1024, 1024, kernel_size=3, stride=2, padding=4),\n","            \n","            nn.AdaptiveAvgPool2d((1, 1)),\n","            \n","            nn.Flatten(),\n","            nn.Linear(in_features=1024, out_features=num_classes)\n","        )\n","        \n","    def forward(self, x):\n","        return self.net(x)"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1, 1000])"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["mobilenet_v1 = MobileNet_v1(3, 1000)\n","\n","image = torch.randn(1, 3, 224, 224)\n","\n","mobilenet_v1(image).shape"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 112, 112]             864\n","       BatchNorm2d-2         [-1, 32, 112, 112]              64\n","              ReLU-3         [-1, 32, 112, 112]               0\n","        Conv_block-4         [-1, 32, 112, 112]               0\n","            Conv2d-5         [-1, 32, 112, 112]             288\n","         Depthwise-6         [-1, 32, 112, 112]               0\n","       BatchNorm2d-7         [-1, 32, 112, 112]              64\n","              ReLU-8         [-1, 32, 112, 112]               0\n","            Conv2d-9         [-1, 64, 112, 112]           2,048\n","      BatchNorm2d-10         [-1, 64, 112, 112]             128\n","             ReLU-11         [-1, 64, 112, 112]               0\n","       Conv_block-12         [-1, 64, 112, 112]               0\n","  Mobile_block_v1-13         [-1, 64, 112, 112]               0\n","           Conv2d-14           [-1, 64, 56, 56]             576\n","        Depthwise-15           [-1, 64, 56, 56]               0\n","      BatchNorm2d-16           [-1, 64, 56, 56]             128\n","             ReLU-17           [-1, 64, 56, 56]               0\n","           Conv2d-18          [-1, 128, 56, 56]           8,192\n","      BatchNorm2d-19          [-1, 128, 56, 56]             256\n","             ReLU-20          [-1, 128, 56, 56]               0\n","       Conv_block-21          [-1, 128, 56, 56]               0\n","  Mobile_block_v1-22          [-1, 128, 56, 56]               0\n","           Conv2d-23          [-1, 128, 56, 56]           1,152\n","        Depthwise-24          [-1, 128, 56, 56]               0\n","      BatchNorm2d-25          [-1, 128, 56, 56]             256\n","             ReLU-26          [-1, 128, 56, 56]               0\n","           Conv2d-27          [-1, 128, 56, 56]          16,384\n","      BatchNorm2d-28          [-1, 128, 56, 56]             256\n","             ReLU-29          [-1, 128, 56, 56]               0\n","       Conv_block-30          [-1, 128, 56, 56]               0\n","  Mobile_block_v1-31          [-1, 128, 56, 56]               0\n","           Conv2d-32          [-1, 128, 28, 28]           1,152\n","        Depthwise-33          [-1, 128, 28, 28]               0\n","      BatchNorm2d-34          [-1, 128, 28, 28]             256\n","             ReLU-35          [-1, 128, 28, 28]               0\n","           Conv2d-36          [-1, 256, 28, 28]          32,768\n","      BatchNorm2d-37          [-1, 256, 28, 28]             512\n","             ReLU-38          [-1, 256, 28, 28]               0\n","       Conv_block-39          [-1, 256, 28, 28]               0\n","  Mobile_block_v1-40          [-1, 256, 28, 28]               0\n","           Conv2d-41          [-1, 256, 28, 28]           2,304\n","        Depthwise-42          [-1, 256, 28, 28]               0\n","      BatchNorm2d-43          [-1, 256, 28, 28]             512\n","             ReLU-44          [-1, 256, 28, 28]               0\n","           Conv2d-45          [-1, 256, 28, 28]          65,536\n","      BatchNorm2d-46          [-1, 256, 28, 28]             512\n","             ReLU-47          [-1, 256, 28, 28]               0\n","       Conv_block-48          [-1, 256, 28, 28]               0\n","  Mobile_block_v1-49          [-1, 256, 28, 28]               0\n","           Conv2d-50          [-1, 256, 14, 14]           2,304\n","        Depthwise-51          [-1, 256, 14, 14]               0\n","      BatchNorm2d-52          [-1, 256, 14, 14]             512\n","             ReLU-53          [-1, 256, 14, 14]               0\n","           Conv2d-54          [-1, 512, 14, 14]         131,072\n","      BatchNorm2d-55          [-1, 512, 14, 14]           1,024\n","             ReLU-56          [-1, 512, 14, 14]               0\n","       Conv_block-57          [-1, 512, 14, 14]               0\n","  Mobile_block_v1-58          [-1, 512, 14, 14]               0\n","           Conv2d-59          [-1, 512, 14, 14]           4,608\n","        Depthwise-60          [-1, 512, 14, 14]               0\n","      BatchNorm2d-61          [-1, 512, 14, 14]           1,024\n","             ReLU-62          [-1, 512, 14, 14]               0\n","           Conv2d-63          [-1, 512, 14, 14]         262,144\n","      BatchNorm2d-64          [-1, 512, 14, 14]           1,024\n","             ReLU-65          [-1, 512, 14, 14]               0\n","       Conv_block-66          [-1, 512, 14, 14]               0\n","  Mobile_block_v1-67          [-1, 512, 14, 14]               0\n","           Conv2d-68          [-1, 512, 14, 14]           4,608\n","        Depthwise-69          [-1, 512, 14, 14]               0\n","      BatchNorm2d-70          [-1, 512, 14, 14]           1,024\n","             ReLU-71          [-1, 512, 14, 14]               0\n","           Conv2d-72          [-1, 512, 14, 14]         262,144\n","      BatchNorm2d-73          [-1, 512, 14, 14]           1,024\n","             ReLU-74          [-1, 512, 14, 14]               0\n","       Conv_block-75          [-1, 512, 14, 14]               0\n","  Mobile_block_v1-76          [-1, 512, 14, 14]               0\n","           Conv2d-77          [-1, 512, 14, 14]           4,608\n","        Depthwise-78          [-1, 512, 14, 14]               0\n","      BatchNorm2d-79          [-1, 512, 14, 14]           1,024\n","             ReLU-80          [-1, 512, 14, 14]               0\n","           Conv2d-81          [-1, 512, 14, 14]         262,144\n","      BatchNorm2d-82          [-1, 512, 14, 14]           1,024\n","             ReLU-83          [-1, 512, 14, 14]               0\n","       Conv_block-84          [-1, 512, 14, 14]               0\n","  Mobile_block_v1-85          [-1, 512, 14, 14]               0\n","           Conv2d-86          [-1, 512, 14, 14]           4,608\n","        Depthwise-87          [-1, 512, 14, 14]               0\n","      BatchNorm2d-88          [-1, 512, 14, 14]           1,024\n","             ReLU-89          [-1, 512, 14, 14]               0\n","           Conv2d-90          [-1, 512, 14, 14]         262,144\n","      BatchNorm2d-91          [-1, 512, 14, 14]           1,024\n","             ReLU-92          [-1, 512, 14, 14]               0\n","       Conv_block-93          [-1, 512, 14, 14]               0\n","  Mobile_block_v1-94          [-1, 512, 14, 14]               0\n","           Conv2d-95          [-1, 512, 14, 14]           4,608\n","        Depthwise-96          [-1, 512, 14, 14]               0\n","      BatchNorm2d-97          [-1, 512, 14, 14]           1,024\n","             ReLU-98          [-1, 512, 14, 14]               0\n","           Conv2d-99          [-1, 512, 14, 14]         262,144\n","     BatchNorm2d-100          [-1, 512, 14, 14]           1,024\n","            ReLU-101          [-1, 512, 14, 14]               0\n","      Conv_block-102          [-1, 512, 14, 14]               0\n"," Mobile_block_v1-103          [-1, 512, 14, 14]               0\n","          Conv2d-104            [-1, 512, 7, 7]           4,608\n","       Depthwise-105            [-1, 512, 7, 7]               0\n","     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n","            ReLU-107            [-1, 512, 7, 7]               0\n","          Conv2d-108           [-1, 1024, 7, 7]         524,288\n","     BatchNorm2d-109           [-1, 1024, 7, 7]           2,048\n","            ReLU-110           [-1, 1024, 7, 7]               0\n","      Conv_block-111           [-1, 1024, 7, 7]               0\n"," Mobile_block_v1-112           [-1, 1024, 7, 7]               0\n","          Conv2d-113           [-1, 1024, 7, 7]           9,216\n","       Depthwise-114           [-1, 1024, 7, 7]               0\n","     BatchNorm2d-115           [-1, 1024, 7, 7]           2,048\n","            ReLU-116           [-1, 1024, 7, 7]               0\n","          Conv2d-117           [-1, 1024, 7, 7]       1,048,576\n","     BatchNorm2d-118           [-1, 1024, 7, 7]           2,048\n","            ReLU-119           [-1, 1024, 7, 7]               0\n","      Conv_block-120           [-1, 1024, 7, 7]               0\n"," Mobile_block_v1-121           [-1, 1024, 7, 7]               0\n","AdaptiveAvgPool2d-122           [-1, 1024, 1, 1]               0\n","         Flatten-123                 [-1, 1024]               0\n","          Linear-124                 [-1, 1000]       1,025,000\n","================================================================\n","Total params: 4,231,976\n","Trainable params: 4,231,976\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 174.59\n","Params size (MB): 16.14\n","Estimated Total Size (MB): 191.30\n","----------------------------------------------------------------\n"]}],"source":["summary(mobilenet_v1, (3, 224, 224))"]},{"cell_type":"markdown","metadata":{},"source":["### Version 2"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class InvertedResidual(nn.Module):\n","    def __init__(self, in_channels, out_channels, t=6, stride=1):\n","        super(InvertedResidual, self).__init__()\n","\n","        self.residual = (in_channels == out_channels) and (stride == 1)\n","\n","        self.relu = nn.ReLU6()\n","\n","        self.bottleneck1 = nn.Conv2d(in_channels, in_channels * t, kernel_size=1, stride=1, padding=0, bias=False)\n","\n","        self.batch_norm1 = nn.BatchNorm2d(in_channels * t)\n","\n","        self.depthwise = Depthwise(in_channels * t, kernel_size=3, stride=stride, bias=False)\n","\n","        self.batch_norm2 = nn.BatchNorm2d(in_channels * t)\n","\n","        self.bottleneck2 = nn.Conv2d(in_channels * t, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n","\n","        self.batch_norm3 = nn.BatchNorm2d(out_channels)\n","\n","    def forward(self, x):\n","        out = self.bottleneck1(x)\n","        out = self.batch_norm1(out)\n","        out = self.relu(out)\n","\n","        out = self.depthwise(out)\n","        out = self.batch_norm2(out)\n","        out = self.relu(out)\n","\n","        out = self.bottleneck2(out)\n","        out = self.batch_norm3(out)\n","\n","        if self.residual:\n","            out += x\n","\n","        return out\n","\n","class MobileNet_v2(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super(MobileNet_v2, self).__init__()\n","        \n","        self.net = nn.Sequential(\n","            Conv_block(in_channels=in_channels, out_channels=32, kernel_size=3, stride=2, padding=1),\n","            InvertedResidual(in_channels=32, out_channels=16, t=1, stride=1),\n","            \n","            InvertedResidual(in_channels=16, out_channels=24, t=6, stride=2),\n","            InvertedResidual(in_channels=24, out_channels=24, t=6, stride=1),\n","            \n","            InvertedResidual(in_channels=24, out_channels=32, t=6, stride=2),\n","            InvertedResidual(in_channels=32, out_channels=32, t=6, stride=1),\n","            InvertedResidual(in_channels=32, out_channels=32, t=6, stride=1),\n","            \n","            InvertedResidual(in_channels=32, out_channels=64, t=6, stride=2),\n","            InvertedResidual(in_channels=64, out_channels=64, t=6, stride=1),\n","            InvertedResidual(in_channels=64, out_channels=64, t=6, stride=1),\n","            InvertedResidual(in_channels=64, out_channels=64, t=6, stride=1),\n","            \n","            InvertedResidual(in_channels=64, out_channels=96, t=6, stride=1),\n","            InvertedResidual(in_channels=96, out_channels=96, t=6, stride=1),\n","            InvertedResidual(in_channels=96, out_channels=96, t=6, stride=1),\n","            \n","            InvertedResidual(in_channels=96, out_channels=160, t=6, stride=2),\n","            InvertedResidual(in_channels=160, out_channels=160, t=6, stride=1),\n","            InvertedResidual(in_channels=160, out_channels=160, t=6, stride=1),\n","            \n","            InvertedResidual(in_channels=160, out_channels=320, t=6, stride=1),\n","            \n","            Conv_block(in_channels=320, out_channels=1280, kernel_size=1),\n","            \n","            nn.AvgPool2d((7, 7)),\n","            \n","            nn.Flatten(),\n","            nn.Dropout(p=0.4),\n","            nn.Linear(in_features=1280, out_features=num_classes)\n","        )\n","            \n","        \n","    def forward(self, x):\n","        return self.net(x)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1, 1000])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["inp = torch.randn(1, 3, 224, 224)\n","\n","mobilenet_v2 = MobileNet_v2(in_channels=3, num_classes=1000)\n","mobilenet_v2(inp).shape"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 112, 112]             864\n","       BatchNorm2d-2         [-1, 32, 112, 112]              64\n","              ReLU-3         [-1, 32, 112, 112]               0\n","        Conv_block-4         [-1, 32, 112, 112]               0\n","            Conv2d-5         [-1, 32, 112, 112]           1,024\n","       BatchNorm2d-6         [-1, 32, 112, 112]              64\n","             ReLU6-7         [-1, 32, 112, 112]               0\n","            Conv2d-8         [-1, 32, 112, 112]             288\n","         Depthwise-9         [-1, 32, 112, 112]               0\n","      BatchNorm2d-10         [-1, 32, 112, 112]              64\n","            ReLU6-11         [-1, 32, 112, 112]               0\n","           Conv2d-12         [-1, 16, 112, 112]             512\n","      BatchNorm2d-13         [-1, 16, 112, 112]              32\n"," InvertedResidual-14         [-1, 16, 112, 112]               0\n","           Conv2d-15         [-1, 96, 112, 112]           1,536\n","      BatchNorm2d-16         [-1, 96, 112, 112]             192\n","            ReLU6-17         [-1, 96, 112, 112]               0\n","           Conv2d-18           [-1, 96, 56, 56]             864\n","        Depthwise-19           [-1, 96, 56, 56]               0\n","      BatchNorm2d-20           [-1, 96, 56, 56]             192\n","            ReLU6-21           [-1, 96, 56, 56]               0\n","           Conv2d-22           [-1, 24, 56, 56]           2,304\n","      BatchNorm2d-23           [-1, 24, 56, 56]              48\n"," InvertedResidual-24           [-1, 24, 56, 56]               0\n","           Conv2d-25          [-1, 144, 56, 56]           3,456\n","      BatchNorm2d-26          [-1, 144, 56, 56]             288\n","            ReLU6-27          [-1, 144, 56, 56]               0\n","           Conv2d-28          [-1, 144, 56, 56]           1,296\n","        Depthwise-29          [-1, 144, 56, 56]               0\n","      BatchNorm2d-30          [-1, 144, 56, 56]             288\n","            ReLU6-31          [-1, 144, 56, 56]               0\n","           Conv2d-32           [-1, 24, 56, 56]           3,456\n","      BatchNorm2d-33           [-1, 24, 56, 56]              48\n"," InvertedResidual-34           [-1, 24, 56, 56]               0\n","           Conv2d-35          [-1, 144, 56, 56]           3,456\n","      BatchNorm2d-36          [-1, 144, 56, 56]             288\n","            ReLU6-37          [-1, 144, 56, 56]               0\n","           Conv2d-38          [-1, 144, 28, 28]           1,296\n","        Depthwise-39          [-1, 144, 28, 28]               0\n","      BatchNorm2d-40          [-1, 144, 28, 28]             288\n","            ReLU6-41          [-1, 144, 28, 28]               0\n","           Conv2d-42           [-1, 32, 28, 28]           4,608\n","      BatchNorm2d-43           [-1, 32, 28, 28]              64\n"," InvertedResidual-44           [-1, 32, 28, 28]               0\n","           Conv2d-45          [-1, 192, 28, 28]           6,144\n","      BatchNorm2d-46          [-1, 192, 28, 28]             384\n","            ReLU6-47          [-1, 192, 28, 28]               0\n","           Conv2d-48          [-1, 192, 28, 28]           1,728\n","        Depthwise-49          [-1, 192, 28, 28]               0\n","      BatchNorm2d-50          [-1, 192, 28, 28]             384\n","            ReLU6-51          [-1, 192, 28, 28]               0\n","           Conv2d-52           [-1, 32, 28, 28]           6,144\n","      BatchNorm2d-53           [-1, 32, 28, 28]              64\n"," InvertedResidual-54           [-1, 32, 28, 28]               0\n","           Conv2d-55          [-1, 192, 28, 28]           6,144\n","      BatchNorm2d-56          [-1, 192, 28, 28]             384\n","            ReLU6-57          [-1, 192, 28, 28]               0\n","           Conv2d-58          [-1, 192, 28, 28]           1,728\n","        Depthwise-59          [-1, 192, 28, 28]               0\n","      BatchNorm2d-60          [-1, 192, 28, 28]             384\n","            ReLU6-61          [-1, 192, 28, 28]               0\n","           Conv2d-62           [-1, 32, 28, 28]           6,144\n","      BatchNorm2d-63           [-1, 32, 28, 28]              64\n"," InvertedResidual-64           [-1, 32, 28, 28]               0\n","           Conv2d-65          [-1, 192, 28, 28]           6,144\n","      BatchNorm2d-66          [-1, 192, 28, 28]             384\n","            ReLU6-67          [-1, 192, 28, 28]               0\n","           Conv2d-68          [-1, 192, 14, 14]           1,728\n","        Depthwise-69          [-1, 192, 14, 14]               0\n","      BatchNorm2d-70          [-1, 192, 14, 14]             384\n","            ReLU6-71          [-1, 192, 14, 14]               0\n","           Conv2d-72           [-1, 64, 14, 14]          12,288\n","      BatchNorm2d-73           [-1, 64, 14, 14]             128\n"," InvertedResidual-74           [-1, 64, 14, 14]               0\n","           Conv2d-75          [-1, 384, 14, 14]          24,576\n","      BatchNorm2d-76          [-1, 384, 14, 14]             768\n","            ReLU6-77          [-1, 384, 14, 14]               0\n","           Conv2d-78          [-1, 384, 14, 14]           3,456\n","        Depthwise-79          [-1, 384, 14, 14]               0\n","      BatchNorm2d-80          [-1, 384, 14, 14]             768\n","            ReLU6-81          [-1, 384, 14, 14]               0\n","           Conv2d-82           [-1, 64, 14, 14]          24,576\n","      BatchNorm2d-83           [-1, 64, 14, 14]             128\n"," InvertedResidual-84           [-1, 64, 14, 14]               0\n","           Conv2d-85          [-1, 384, 14, 14]          24,576\n","      BatchNorm2d-86          [-1, 384, 14, 14]             768\n","            ReLU6-87          [-1, 384, 14, 14]               0\n","           Conv2d-88          [-1, 384, 14, 14]           3,456\n","        Depthwise-89          [-1, 384, 14, 14]               0\n","      BatchNorm2d-90          [-1, 384, 14, 14]             768\n","            ReLU6-91          [-1, 384, 14, 14]               0\n","           Conv2d-92           [-1, 64, 14, 14]          24,576\n","      BatchNorm2d-93           [-1, 64, 14, 14]             128\n"," InvertedResidual-94           [-1, 64, 14, 14]               0\n","           Conv2d-95          [-1, 384, 14, 14]          24,576\n","      BatchNorm2d-96          [-1, 384, 14, 14]             768\n","            ReLU6-97          [-1, 384, 14, 14]               0\n","           Conv2d-98          [-1, 384, 14, 14]           3,456\n","        Depthwise-99          [-1, 384, 14, 14]               0\n","     BatchNorm2d-100          [-1, 384, 14, 14]             768\n","           ReLU6-101          [-1, 384, 14, 14]               0\n","          Conv2d-102           [-1, 64, 14, 14]          24,576\n","     BatchNorm2d-103           [-1, 64, 14, 14]             128\n","InvertedResidual-104           [-1, 64, 14, 14]               0\n","          Conv2d-105          [-1, 384, 14, 14]          24,576\n","     BatchNorm2d-106          [-1, 384, 14, 14]             768\n","           ReLU6-107          [-1, 384, 14, 14]               0\n","          Conv2d-108          [-1, 384, 14, 14]           3,456\n","       Depthwise-109          [-1, 384, 14, 14]               0\n","     BatchNorm2d-110          [-1, 384, 14, 14]             768\n","           ReLU6-111          [-1, 384, 14, 14]               0\n","          Conv2d-112           [-1, 96, 14, 14]          36,864\n","     BatchNorm2d-113           [-1, 96, 14, 14]             192\n","InvertedResidual-114           [-1, 96, 14, 14]               0\n","          Conv2d-115          [-1, 576, 14, 14]          55,296\n","     BatchNorm2d-116          [-1, 576, 14, 14]           1,152\n","           ReLU6-117          [-1, 576, 14, 14]               0\n","          Conv2d-118          [-1, 576, 14, 14]           5,184\n","       Depthwise-119          [-1, 576, 14, 14]               0\n","     BatchNorm2d-120          [-1, 576, 14, 14]           1,152\n","           ReLU6-121          [-1, 576, 14, 14]               0\n","          Conv2d-122           [-1, 96, 14, 14]          55,296\n","     BatchNorm2d-123           [-1, 96, 14, 14]             192\n","InvertedResidual-124           [-1, 96, 14, 14]               0\n","          Conv2d-125          [-1, 576, 14, 14]          55,296\n","     BatchNorm2d-126          [-1, 576, 14, 14]           1,152\n","           ReLU6-127          [-1, 576, 14, 14]               0\n","          Conv2d-128          [-1, 576, 14, 14]           5,184\n","       Depthwise-129          [-1, 576, 14, 14]               0\n","     BatchNorm2d-130          [-1, 576, 14, 14]           1,152\n","           ReLU6-131          [-1, 576, 14, 14]               0\n","          Conv2d-132           [-1, 96, 14, 14]          55,296\n","     BatchNorm2d-133           [-1, 96, 14, 14]             192\n","InvertedResidual-134           [-1, 96, 14, 14]               0\n","          Conv2d-135          [-1, 576, 14, 14]          55,296\n","     BatchNorm2d-136          [-1, 576, 14, 14]           1,152\n","           ReLU6-137          [-1, 576, 14, 14]               0\n","          Conv2d-138            [-1, 576, 7, 7]           5,184\n","       Depthwise-139            [-1, 576, 7, 7]               0\n","     BatchNorm2d-140            [-1, 576, 7, 7]           1,152\n","           ReLU6-141            [-1, 576, 7, 7]               0\n","          Conv2d-142            [-1, 160, 7, 7]          92,160\n","     BatchNorm2d-143            [-1, 160, 7, 7]             320\n","InvertedResidual-144            [-1, 160, 7, 7]               0\n","          Conv2d-145            [-1, 960, 7, 7]         153,600\n","     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n","           ReLU6-147            [-1, 960, 7, 7]               0\n","          Conv2d-148            [-1, 960, 7, 7]           8,640\n","       Depthwise-149            [-1, 960, 7, 7]               0\n","     BatchNorm2d-150            [-1, 960, 7, 7]           1,920\n","           ReLU6-151            [-1, 960, 7, 7]               0\n","          Conv2d-152            [-1, 160, 7, 7]         153,600\n","     BatchNorm2d-153            [-1, 160, 7, 7]             320\n","InvertedResidual-154            [-1, 160, 7, 7]               0\n","          Conv2d-155            [-1, 960, 7, 7]         153,600\n","     BatchNorm2d-156            [-1, 960, 7, 7]           1,920\n","           ReLU6-157            [-1, 960, 7, 7]               0\n","          Conv2d-158            [-1, 960, 7, 7]           8,640\n","       Depthwise-159            [-1, 960, 7, 7]               0\n","     BatchNorm2d-160            [-1, 960, 7, 7]           1,920\n","           ReLU6-161            [-1, 960, 7, 7]               0\n","          Conv2d-162            [-1, 160, 7, 7]         153,600\n","     BatchNorm2d-163            [-1, 160, 7, 7]             320\n","InvertedResidual-164            [-1, 160, 7, 7]               0\n","          Conv2d-165            [-1, 960, 7, 7]         153,600\n","     BatchNorm2d-166            [-1, 960, 7, 7]           1,920\n","           ReLU6-167            [-1, 960, 7, 7]               0\n","          Conv2d-168            [-1, 960, 7, 7]           8,640\n","       Depthwise-169            [-1, 960, 7, 7]               0\n","     BatchNorm2d-170            [-1, 960, 7, 7]           1,920\n","           ReLU6-171            [-1, 960, 7, 7]               0\n","          Conv2d-172            [-1, 320, 7, 7]         307,200\n","     BatchNorm2d-173            [-1, 320, 7, 7]             640\n","InvertedResidual-174            [-1, 320, 7, 7]               0\n","          Conv2d-175           [-1, 1280, 7, 7]         409,600\n","     BatchNorm2d-176           [-1, 1280, 7, 7]           2,560\n","            ReLU-177           [-1, 1280, 7, 7]               0\n","      Conv_block-178           [-1, 1280, 7, 7]               0\n","       AvgPool2d-179           [-1, 1280, 1, 1]               0\n","         Flatten-180                 [-1, 1280]               0\n","         Dropout-181                 [-1, 1280]               0\n","          Linear-182                 [-1, 1000]       1,281,000\n","================================================================\n","Total params: 3,505,960\n","Trainable params: 3,505,960\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 183.18\n","Params size (MB): 13.37\n","Estimated Total Size (MB): 197.13\n","----------------------------------------------------------------\n"]}],"source":["summary(mobilenet_v2, (3, 224, 224))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
