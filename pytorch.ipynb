{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ahmedwael2000/pytorch?scriptVersionId=139142743\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2023-08-07T04:44:44.257533Z","iopub.execute_input":"2023-08-07T04:44:44.257879Z","iopub.status.idle":"2023-08-07T04:44:54.524921Z","shell.execute_reply.started":"2023-08-07T04:44:44.257852Z","shell.execute_reply":"2023-08-07T04:44:54.523812Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import os \nimport torch\nimport cv2 as cv\nimport torchvision\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom torchsummary import summary\nimport torchvision.transforms as T\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"execution":{"iopub.status.busy":"2023-08-07T04:44:54.528251Z","iopub.execute_input":"2023-08-07T04:44:54.528614Z","iopub.status.idle":"2023-08-07T04:44:54.536852Z","shell.execute_reply.started":"2023-08-07T04:44:54.528579Z","shell.execute_reply":"2023-08-07T04:44:54.53589Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data_path = '/kaggle/input/butterfly-image-classification'\n\ntest_path = os.path.join(data_path, 'test')\ntrain_path = os.path.join(data_path, 'train')\n\ntrain_df = pd.read_csv(os.path.join(data_path, 'Training_set.csv'))\ntest_df = pd.read_csv(os.path.join(data_path, 'Testing_set.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:46:20.697628Z","iopub.execute_input":"2023-08-06T19:46:20.699288Z","iopub.status.idle":"2023-08-06T19:46:20.747507Z","shell.execute_reply.started":"2023-08-06T19:46:20.699214Z","shell.execute_reply":"2023-08-06T19:46:20.746297Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# converting type of columns to 'category'\ntrain_df['label'] = train_df['label'].astype('category')\n\n# Assigning numerical values and storing in another column\ntrain_df['encoded_label'] = train_df['label'].cat.codes\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:46:21.219882Z","iopub.execute_input":"2023-08-06T19:46:21.220612Z","iopub.status.idle":"2023-08-06T19:46:21.258772Z","shell.execute_reply.started":"2023-08-06T19:46:21.220576Z","shell.execute_reply":"2023-08-06T19:46:21.257397Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"      filename                     label  encoded_label\n0  Image_1.jpg          SOUTHERN DOGFACE             66\n1  Image_2.jpg                    ADONIS              0\n2  Image_3.jpg            BROWN SIPROETA             12\n3  Image_4.jpg                   MONARCH             44\n4  Image_5.jpg  GREEN CELLED CATTLEHEART             33","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n      <th>encoded_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_1.jpg</td>\n      <td>SOUTHERN DOGFACE</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_2.jpg</td>\n      <td>ADONIS</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_3.jpg</td>\n      <td>BROWN SIPROETA</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_4.jpg</td>\n      <td>MONARCH</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_5.jpg</td>\n      <td>GREEN CELLED CATTLEHEART</td>\n      <td>33</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, csv_file, data_path, transforms=None):\n        self.annotations = csv_file\n        self.data_path = data_path\n        self.transforms = transforms\n        self.num_classes = len(self.annotations.label.unique())\n        \n    def __getitem__(self, i):\n        image_path = os.path.join(self.data_path, self.annotations.iloc[i, 0])\n        image = read_image(image_path)\n        label = F.one_hot(torch.tensor(self.annotations.encoded_label[i], dtype=int), num_classes=self.num_classes)\n        label = label.type(torch.float)\n        if self.transforms:\n            image = self.transforms(image)\n        return (image, label)\n    \n    def __len__(self):\n        return len(self.annotations)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:46:47.953715Z","iopub.execute_input":"2023-08-06T19:46:47.954107Z","iopub.status.idle":"2023-08-06T19:46:47.964361Z","shell.execute_reply.started":"2023-08-06T19:46:47.954077Z","shell.execute_reply":"2023-08-06T19:46:47.962899Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def add_gaussian_noise(image):\n    mean = np.random.uniform(low=-2.0, high=2.0)\n    std = np.random.uniform(low=1.0, high=10.0)\n    noise = torch.randn(image.size()) * std + mean\n    return image / 255.0 + noise / 255.0\n\naugment = T.Compose([\n    T.RandomHorizontalFlip(p=0.5),\n    T.RandomRotation(degrees=(-30, 30)),\n    T.RandomCrop(size=(224, 224)),\n    add_gaussian_noise\n])\n\ndataset = CustomDataset(train_df, train_path, augment)\n\ntrain_size = int(0.85 * len(dataset))\ncv_size = len(dataset) - train_size\ntrain_dataset, cv_dataset = torch.utils.data.random_split(dataset, [train_size, cv_size])","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:46:50.070724Z","iopub.execute_input":"2023-08-06T19:46:50.071603Z","iopub.status.idle":"2023-08-06T19:46:50.10868Z","shell.execute_reply.started":"2023-08-06T19:46:50.071559Z","shell.execute_reply":"2023-08-06T19:46:50.107698Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# data loader\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\ncv_loader = DataLoader(cv_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:46:51.777214Z","iopub.execute_input":"2023-08-06T19:46:51.777679Z","iopub.status.idle":"2023-08-06T19:46:51.784816Z","shell.execute_reply.started":"2023-08-06T19:46:51.777641Z","shell.execute_reply":"2023-08-06T19:46:51.783525Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# models  \n\n## VGG19, ResNet18, MobileNet, GoogLeNet (InceptionNet), EfficientNet\n","metadata":{}},{"cell_type":"code","source":"# VGG19: \nclass VGG19(nn.Module):\n    def __init__(self, in_channels, num_classes):\n        super(VGG19, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(in_channels, 64, 3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, 3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, stride=2),\n\n            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, stride=2),\n\n            nn.Conv2d(128,256,3,stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256,256,3,stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256,256,3,stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256,256,3,stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, stride=2),\n\n            nn.Conv2d(256,512,3,stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512,512,3,stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512,512,3,stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512,512,3,stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, stride=2),\n\n            nn.Conv2d(512,512,3,stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512,512,3,stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512,512,3,stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512,512,3,stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, stride=2),\n\n            nn.Flatten(),\n            nn.Linear(in_features=512*7*7, out_features=4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(in_features=4096, out_features=4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(in_features=4096, out_features=num_classes)\n        )\n        \n    def forward(self, x):\n        return self.model(x)\n    \nvgg19 = VGG19(3, 1000).to(device)\nsummary(vgg19, (3, 224, 224))","metadata":{"execution":{"iopub.status.busy":"2023-08-06T06:28:11.733455Z","iopub.execute_input":"2023-08-06T06:28:11.733842Z","iopub.status.idle":"2023-08-06T06:28:27.66637Z","shell.execute_reply.started":"2023-08-06T06:28:11.733808Z","shell.execute_reply":"2023-08-06T06:28:27.665447Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 224, 224]           1,792\n              ReLU-2         [-1, 64, 224, 224]               0\n            Conv2d-3         [-1, 64, 224, 224]          36,928\n              ReLU-4         [-1, 64, 224, 224]               0\n         MaxPool2d-5         [-1, 64, 112, 112]               0\n            Conv2d-6        [-1, 128, 112, 112]          73,856\n              ReLU-7        [-1, 128, 112, 112]               0\n            Conv2d-8        [-1, 128, 112, 112]         147,584\n              ReLU-9        [-1, 128, 112, 112]               0\n        MaxPool2d-10          [-1, 128, 56, 56]               0\n           Conv2d-11          [-1, 256, 56, 56]         295,168\n             ReLU-12          [-1, 256, 56, 56]               0\n           Conv2d-13          [-1, 256, 56, 56]         590,080\n             ReLU-14          [-1, 256, 56, 56]               0\n           Conv2d-15          [-1, 256, 56, 56]         590,080\n             ReLU-16          [-1, 256, 56, 56]               0\n           Conv2d-17          [-1, 256, 56, 56]         590,080\n             ReLU-18          [-1, 256, 56, 56]               0\n        MaxPool2d-19          [-1, 256, 28, 28]               0\n           Conv2d-20          [-1, 512, 28, 28]       1,180,160\n             ReLU-21          [-1, 512, 28, 28]               0\n           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n             ReLU-23          [-1, 512, 28, 28]               0\n           Conv2d-24          [-1, 512, 28, 28]       2,359,808\n             ReLU-25          [-1, 512, 28, 28]               0\n           Conv2d-26          [-1, 512, 28, 28]       2,359,808\n             ReLU-27          [-1, 512, 28, 28]               0\n        MaxPool2d-28          [-1, 512, 14, 14]               0\n           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n             ReLU-30          [-1, 512, 14, 14]               0\n           Conv2d-31          [-1, 512, 14, 14]       2,359,808\n             ReLU-32          [-1, 512, 14, 14]               0\n           Conv2d-33          [-1, 512, 14, 14]       2,359,808\n             ReLU-34          [-1, 512, 14, 14]               0\n           Conv2d-35          [-1, 512, 14, 14]       2,359,808\n             ReLU-36          [-1, 512, 14, 14]               0\n        MaxPool2d-37            [-1, 512, 7, 7]               0\n          Flatten-38                [-1, 25088]               0\n           Linear-39                 [-1, 4096]     102,764,544\n             ReLU-40                 [-1, 4096]               0\n          Dropout-41                 [-1, 4096]               0\n           Linear-42                 [-1, 4096]      16,781,312\n             ReLU-43                 [-1, 4096]               0\n          Dropout-44                 [-1, 4096]               0\n           Linear-45                 [-1, 1000]       4,097,000\n================================================================\nTotal params: 143,667,240\nTrainable params: 143,667,240\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 238.69\nParams size (MB): 548.05\nEstimated Total Size (MB): 787.31\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the pretrained VGG19 model\npretrained_vgg19 = models.vgg19(pretrained=True).to(device)\nsummary(pretrained_vgg19, (3, 224, 224))","metadata":{"execution":{"iopub.status.busy":"2023-08-06T06:30:06.651079Z","iopub.execute_input":"2023-08-06T06:30:06.65143Z","iopub.status.idle":"2023-08-06T06:30:08.615587Z","shell.execute_reply.started":"2023-08-06T06:30:06.651402Z","shell.execute_reply":"2023-08-06T06:30:08.614534Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 224, 224]           1,792\n              ReLU-2         [-1, 64, 224, 224]               0\n            Conv2d-3         [-1, 64, 224, 224]          36,928\n              ReLU-4         [-1, 64, 224, 224]               0\n         MaxPool2d-5         [-1, 64, 112, 112]               0\n            Conv2d-6        [-1, 128, 112, 112]          73,856\n              ReLU-7        [-1, 128, 112, 112]               0\n            Conv2d-8        [-1, 128, 112, 112]         147,584\n              ReLU-9        [-1, 128, 112, 112]               0\n        MaxPool2d-10          [-1, 128, 56, 56]               0\n           Conv2d-11          [-1, 256, 56, 56]         295,168\n             ReLU-12          [-1, 256, 56, 56]               0\n           Conv2d-13          [-1, 256, 56, 56]         590,080\n             ReLU-14          [-1, 256, 56, 56]               0\n           Conv2d-15          [-1, 256, 56, 56]         590,080\n             ReLU-16          [-1, 256, 56, 56]               0\n           Conv2d-17          [-1, 256, 56, 56]         590,080\n             ReLU-18          [-1, 256, 56, 56]               0\n        MaxPool2d-19          [-1, 256, 28, 28]               0\n           Conv2d-20          [-1, 512, 28, 28]       1,180,160\n             ReLU-21          [-1, 512, 28, 28]               0\n           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n             ReLU-23          [-1, 512, 28, 28]               0\n           Conv2d-24          [-1, 512, 28, 28]       2,359,808\n             ReLU-25          [-1, 512, 28, 28]               0\n           Conv2d-26          [-1, 512, 28, 28]       2,359,808\n             ReLU-27          [-1, 512, 28, 28]               0\n        MaxPool2d-28          [-1, 512, 14, 14]               0\n           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n             ReLU-30          [-1, 512, 14, 14]               0\n           Conv2d-31          [-1, 512, 14, 14]       2,359,808\n             ReLU-32          [-1, 512, 14, 14]               0\n           Conv2d-33          [-1, 512, 14, 14]       2,359,808\n             ReLU-34          [-1, 512, 14, 14]               0\n           Conv2d-35          [-1, 512, 14, 14]       2,359,808\n             ReLU-36          [-1, 512, 14, 14]               0\n        MaxPool2d-37            [-1, 512, 7, 7]               0\nAdaptiveAvgPool2d-38            [-1, 512, 7, 7]               0\n           Linear-39                 [-1, 4096]     102,764,544\n             ReLU-40                 [-1, 4096]               0\n          Dropout-41                 [-1, 4096]               0\n           Linear-42                 [-1, 4096]      16,781,312\n             ReLU-43                 [-1, 4096]               0\n          Dropout-44                 [-1, 4096]               0\n           Linear-45                 [-1, 1000]       4,097,000\n================================================================\nTotal params: 143,667,240\nTrainable params: 143,667,240\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 238.69\nParams size (MB): 548.05\nEstimated Total Size (MB): 787.31\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loop over the layers of the model\nfor name, layer in list(pretrained_vgg19.named_children()):\n    # We can freeze all these layers as they are already pre-trained\n    print(name) # just displaying the name of each layer\n\n# We need to classify 75 classes!!\nnum_classes = 75\n\n# Delete the last layer (classifier)\npretrained_vgg19 = nn.Sequential(\n    *list(pretrained_vgg19.children())[:-1],\n    nn.Flatten(),\n    *list(pretrained_vgg19.children())[-1][:-1],\n).to(device)\n\n# Insert a custom linear layer at the end for predicting 75 classes\ncustom_linear_layer = nn.Linear(in_features=4096, out_features=num_classes).to(device)\n\npretrained_vgg19.add_module('custom_linear', custom_linear_layer)\nsummary(pretrained_vgg19, (3, 224, 224))","metadata":{"execution":{"iopub.status.busy":"2023-08-06T06:30:08.617603Z","iopub.execute_input":"2023-08-06T06:30:08.618145Z","iopub.status.idle":"2023-08-06T06:30:08.644961Z","shell.execute_reply.started":"2023-08-06T06:30:08.618108Z","shell.execute_reply":"2023-08-06T06:30:08.643948Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"features\navgpool\nclassifier\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 224, 224]           1,792\n              ReLU-2         [-1, 64, 224, 224]               0\n            Conv2d-3         [-1, 64, 224, 224]          36,928\n              ReLU-4         [-1, 64, 224, 224]               0\n         MaxPool2d-5         [-1, 64, 112, 112]               0\n            Conv2d-6        [-1, 128, 112, 112]          73,856\n              ReLU-7        [-1, 128, 112, 112]               0\n            Conv2d-8        [-1, 128, 112, 112]         147,584\n              ReLU-9        [-1, 128, 112, 112]               0\n        MaxPool2d-10          [-1, 128, 56, 56]               0\n           Conv2d-11          [-1, 256, 56, 56]         295,168\n             ReLU-12          [-1, 256, 56, 56]               0\n           Conv2d-13          [-1, 256, 56, 56]         590,080\n             ReLU-14          [-1, 256, 56, 56]               0\n           Conv2d-15          [-1, 256, 56, 56]         590,080\n             ReLU-16          [-1, 256, 56, 56]               0\n           Conv2d-17          [-1, 256, 56, 56]         590,080\n             ReLU-18          [-1, 256, 56, 56]               0\n        MaxPool2d-19          [-1, 256, 28, 28]               0\n           Conv2d-20          [-1, 512, 28, 28]       1,180,160\n             ReLU-21          [-1, 512, 28, 28]               0\n           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n             ReLU-23          [-1, 512, 28, 28]               0\n           Conv2d-24          [-1, 512, 28, 28]       2,359,808\n             ReLU-25          [-1, 512, 28, 28]               0\n           Conv2d-26          [-1, 512, 28, 28]       2,359,808\n             ReLU-27          [-1, 512, 28, 28]               0\n        MaxPool2d-28          [-1, 512, 14, 14]               0\n           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n             ReLU-30          [-1, 512, 14, 14]               0\n           Conv2d-31          [-1, 512, 14, 14]       2,359,808\n             ReLU-32          [-1, 512, 14, 14]               0\n           Conv2d-33          [-1, 512, 14, 14]       2,359,808\n             ReLU-34          [-1, 512, 14, 14]               0\n           Conv2d-35          [-1, 512, 14, 14]       2,359,808\n             ReLU-36          [-1, 512, 14, 14]               0\n        MaxPool2d-37            [-1, 512, 7, 7]               0\nAdaptiveAvgPool2d-38            [-1, 512, 7, 7]               0\n          Flatten-39                [-1, 25088]               0\n           Linear-40                 [-1, 4096]     102,764,544\n             ReLU-41                 [-1, 4096]               0\n          Dropout-42                 [-1, 4096]               0\n           Linear-43                 [-1, 4096]      16,781,312\n             ReLU-44                 [-1, 4096]               0\n          Dropout-45                 [-1, 4096]               0\n           Linear-46                   [-1, 75]         307,275\n================================================================\nTotal params: 139,877,515\nTrainable params: 139,877,515\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 238.87\nParams size (MB): 533.59\nEstimated Total Size (MB): 773.04\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(pretrained_vgg19.parameters(), lr=1e-4, weight_decay=1e-2)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T06:30:23.046956Z","iopub.execute_input":"2023-08-06T06:30:23.047327Z","iopub.status.idle":"2023-08-06T06:30:23.053127Z","shell.execute_reply.started":"2023-08-06T06:30:23.047296Z","shell.execute_reply":"2023-08-06T06:30:23.051909Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def train_model(train_loader, model, criterion, optimizer, device='cpu', epochs=10):\n    model.train()\n    for epoch in range(epochs):\n        for images, target in train_loader:\n            output = model(images.to(device))\n            \n            optimizer.zero_grad()\n            \n            loss = criterion(output, target.to(device))\n            loss.backward()\n            \n            optimizer.step()\n            \n        if epoch % 5 == 0:\n            print(f'epoch {epoch}: loss: {loss}')\n            \n    print(f'training end, loss: {loss}')\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-06T06:31:10.225958Z","iopub.execute_input":"2023-08-06T06:31:10.22634Z","iopub.status.idle":"2023-08-06T06:31:10.233431Z","shell.execute_reply.started":"2023-08-06T06:31:10.226312Z","shell.execute_reply":"2023-08-06T06:31:10.232479Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"new_VGG19 = train_model(train_loader, pretrained_vgg19, criterion, optimizer, device=device, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T06:31:10.492965Z","iopub.execute_input":"2023-08-06T06:31:10.494133Z","iopub.status.idle":"2023-08-06T07:07:42.99133Z","shell.execute_reply.started":"2023-08-06T06:31:10.494088Z","shell.execute_reply":"2023-08-06T07:07:42.990346Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"epoch 0: loss: 1.068445086479187\nepoch 5: loss: 0.6951164603233337\nepoch 10: loss: 0.015174373053014278\nepoch 15: loss: 0.0018582374323159456\ntraining end, loss: 0.09725723415613174\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving our trained model\n\ntorch.save(new_VGG19.state_dict(), 'trained_vgg19.pth')","metadata":{"execution":{"iopub.status.busy":"2023-08-06T07:10:23.036216Z","iopub.execute_input":"2023-08-06T07:10:23.036587Z","iopub.status.idle":"2023-08-06T07:10:24.109518Z","shell.execute_reply.started":"2023-08-06T07:10:23.036558Z","shell.execute_reply":"2023-08-06T07:10:24.108404Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# ResNet18","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inception Module","metadata":{}},{"cell_type":"code","source":"# Inception Model (GoogLeNet)\n\nclass Conv_block(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, padding=0, stride=1):\n        super(Conv_block, self).__init__()\n        \n        self.conv_block = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU()\n        )\n        \n    def forward(self, x):\n        return self.conv_block(x)\n        \n\nclass Inception_block(nn.Module):\n    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, pool_1x1):\n        super(Inception_block, self).__init__()\n        self.branch1 = Conv_block(in_channels, out_1x1, kernel_size=1)\n        \n        self.branch2 = nn.Sequential(\n            Conv_block(in_channels, red_3x3, kernel_size=1),\n            Conv_block(red_3x3, out_3x3, kernel_size=3, padding=1)\n        )\n        \n        self.branch3 = nn.Sequential(\n            Conv_block(in_channels, red_5x5, kernel_size=1),\n            Conv_block(red_5x5, out_5x5, kernel_size=5, padding=2)\n        )\n        \n        self.branch4 = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n            Conv_block(in_channels, pool_1x1, kernel_size=1)\n        )\n        \n    def forward(self, x):\n        branch1 = self.branch1(x)\n        branch2 = self.branch2(x)\n        branch3 = self.branch3(x)\n        branch4 = self.branch4(x)\n        \n        return torch.concat([branch1, branch2, branch3, branch4], dim=1) # (batch_size, n_channels, height, width) (1, 3, 224, 224)\n    \n\nclass Inception_Net(nn.Module):\n    def __init__(self, in_channels, num_classes):\n        super(Inception_Net, self).__init__()\n        self.conv_block1 = Conv_block(in_channels, 64, kernel_size=7, stride=2, padding=3)\n        \n        self.max_pool = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n        \n        self.conv_block2 = Conv_block(64, 192, kernel_size=3, stride=1, padding=1)\n        \n        # in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, pool_1x1\n        self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\n        self.inception3b = Inception_block(256, 128, 128, 192, 32, 96, 64)\n        \n        self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\n        self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\n        self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\n        self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\n        self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128)\n        \n        self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\n        self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\n        \n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        \n        self.dropout = nn.Dropout(p=0.4)\n        \n        self.fc = nn.Linear(in_features=1024, out_features=num_classes)\n        \n    def forward(self, x):\n        return nn.Sequential(\n            self.conv_block1,\n            self.max_pool,\n            self.conv_block2,\n            self.max_pool,\n            self.inception3a,\n            self.inception3b,\n            self.max_pool,\n            self.inception4a,\n            self.inception4b,\n            self.inception4c,\n            self.inception4d,\n            self.inception4e,\n            self.max_pool,\n            self.inception5a,\n            self.inception5b,\n            self.avg_pool,\n            self.dropout,\n            nn.Flatten(),\n            self.fc\n        )(x)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T05:00:56.296436Z","iopub.execute_input":"2023-08-07T05:00:56.296863Z","iopub.status.idle":"2023-08-07T05:00:56.318885Z","shell.execute_reply.started":"2023-08-07T05:00:56.296838Z","shell.execute_reply":"2023-08-07T05:00:56.31695Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"m = nn.AdaptiveAvgPool2d((5, 7))\ninp = torch.randn(1, 64, 3, 20)\noutput = m(inp)\n\noutput.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-07T05:42:18.151802Z","iopub.execute_input":"2023-08-07T05:42:18.152797Z","iopub.status.idle":"2023-08-07T05:42:18.160822Z","shell.execute_reply.started":"2023-08-07T05:42:18.152744Z","shell.execute_reply":"2023-08-07T05:42:18.159928Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 64, 5, 7])"},"metadata":{}}]},{"cell_type":"code","source":"Net = Inception_Net(3, 1000)\n\nx = torch.randn(1, 3, 224, 224)\n\nNet(x).shape","metadata":{"execution":{"iopub.status.busy":"2023-08-07T05:00:58.345462Z","iopub.execute_input":"2023-08-07T05:00:58.345909Z","iopub.status.idle":"2023-08-07T05:00:58.751291Z","shell.execute_reply.started":"2023-08-07T05:00:58.345862Z","shell.execute_reply":"2023-08-07T05:00:58.746577Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 1000])"},"metadata":{}}]},{"cell_type":"code","source":"summary(Net, (3, 224, 224))","metadata":{"execution":{"iopub.status.busy":"2023-08-07T05:04:22.366339Z","iopub.execute_input":"2023-08-07T05:04:22.367339Z","iopub.status.idle":"2023-08-07T05:04:22.572154Z","shell.execute_reply.started":"2023-08-07T05:04:22.367288Z","shell.execute_reply":"2023-08-07T05:04:22.571237Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 112, 112]           9,408\n       BatchNorm2d-2         [-1, 64, 112, 112]             128\n              ReLU-3         [-1, 64, 112, 112]               0\n        Conv_block-4         [-1, 64, 112, 112]               0\n         MaxPool2d-5           [-1, 64, 56, 56]               0\n            Conv2d-6          [-1, 192, 56, 56]         110,592\n       BatchNorm2d-7          [-1, 192, 56, 56]             384\n              ReLU-8          [-1, 192, 56, 56]               0\n        Conv_block-9          [-1, 192, 56, 56]               0\n        MaxPool2d-10          [-1, 192, 28, 28]               0\n           Conv2d-11           [-1, 64, 28, 28]          12,288\n      BatchNorm2d-12           [-1, 64, 28, 28]             128\n             ReLU-13           [-1, 64, 28, 28]               0\n       Conv_block-14           [-1, 64, 28, 28]               0\n           Conv2d-15           [-1, 96, 28, 28]          18,432\n      BatchNorm2d-16           [-1, 96, 28, 28]             192\n             ReLU-17           [-1, 96, 28, 28]               0\n       Conv_block-18           [-1, 96, 28, 28]               0\n           Conv2d-19          [-1, 128, 28, 28]         110,592\n      BatchNorm2d-20          [-1, 128, 28, 28]             256\n             ReLU-21          [-1, 128, 28, 28]               0\n       Conv_block-22          [-1, 128, 28, 28]               0\n           Conv2d-23           [-1, 16, 28, 28]           3,072\n      BatchNorm2d-24           [-1, 16, 28, 28]              32\n             ReLU-25           [-1, 16, 28, 28]               0\n       Conv_block-26           [-1, 16, 28, 28]               0\n           Conv2d-27           [-1, 32, 28, 28]          12,800\n      BatchNorm2d-28           [-1, 32, 28, 28]              64\n             ReLU-29           [-1, 32, 28, 28]               0\n       Conv_block-30           [-1, 32, 28, 28]               0\n        MaxPool2d-31          [-1, 192, 28, 28]               0\n           Conv2d-32           [-1, 32, 28, 28]           6,144\n      BatchNorm2d-33           [-1, 32, 28, 28]              64\n             ReLU-34           [-1, 32, 28, 28]               0\n       Conv_block-35           [-1, 32, 28, 28]               0\n  Inception_block-36          [-1, 256, 28, 28]               0\n           Conv2d-37          [-1, 128, 28, 28]          32,768\n      BatchNorm2d-38          [-1, 128, 28, 28]             256\n             ReLU-39          [-1, 128, 28, 28]               0\n       Conv_block-40          [-1, 128, 28, 28]               0\n           Conv2d-41          [-1, 128, 28, 28]          32,768\n      BatchNorm2d-42          [-1, 128, 28, 28]             256\n             ReLU-43          [-1, 128, 28, 28]               0\n       Conv_block-44          [-1, 128, 28, 28]               0\n           Conv2d-45          [-1, 192, 28, 28]         221,184\n      BatchNorm2d-46          [-1, 192, 28, 28]             384\n             ReLU-47          [-1, 192, 28, 28]               0\n       Conv_block-48          [-1, 192, 28, 28]               0\n           Conv2d-49           [-1, 32, 28, 28]           8,192\n      BatchNorm2d-50           [-1, 32, 28, 28]              64\n             ReLU-51           [-1, 32, 28, 28]               0\n       Conv_block-52           [-1, 32, 28, 28]               0\n           Conv2d-53           [-1, 96, 28, 28]          76,800\n      BatchNorm2d-54           [-1, 96, 28, 28]             192\n             ReLU-55           [-1, 96, 28, 28]               0\n       Conv_block-56           [-1, 96, 28, 28]               0\n        MaxPool2d-57          [-1, 256, 28, 28]               0\n           Conv2d-58           [-1, 64, 28, 28]          16,384\n      BatchNorm2d-59           [-1, 64, 28, 28]             128\n             ReLU-60           [-1, 64, 28, 28]               0\n       Conv_block-61           [-1, 64, 28, 28]               0\n  Inception_block-62          [-1, 480, 28, 28]               0\n        MaxPool2d-63          [-1, 480, 14, 14]               0\n           Conv2d-64          [-1, 192, 14, 14]          92,160\n      BatchNorm2d-65          [-1, 192, 14, 14]             384\n             ReLU-66          [-1, 192, 14, 14]               0\n       Conv_block-67          [-1, 192, 14, 14]               0\n           Conv2d-68           [-1, 96, 14, 14]          46,080\n      BatchNorm2d-69           [-1, 96, 14, 14]             192\n             ReLU-70           [-1, 96, 14, 14]               0\n       Conv_block-71           [-1, 96, 14, 14]               0\n           Conv2d-72          [-1, 208, 14, 14]         179,712\n      BatchNorm2d-73          [-1, 208, 14, 14]             416\n             ReLU-74          [-1, 208, 14, 14]               0\n       Conv_block-75          [-1, 208, 14, 14]               0\n           Conv2d-76           [-1, 16, 14, 14]           7,680\n      BatchNorm2d-77           [-1, 16, 14, 14]              32\n             ReLU-78           [-1, 16, 14, 14]               0\n       Conv_block-79           [-1, 16, 14, 14]               0\n           Conv2d-80           [-1, 48, 14, 14]          19,200\n      BatchNorm2d-81           [-1, 48, 14, 14]              96\n             ReLU-82           [-1, 48, 14, 14]               0\n       Conv_block-83           [-1, 48, 14, 14]               0\n        MaxPool2d-84          [-1, 480, 14, 14]               0\n           Conv2d-85           [-1, 64, 14, 14]          30,720\n      BatchNorm2d-86           [-1, 64, 14, 14]             128\n             ReLU-87           [-1, 64, 14, 14]               0\n       Conv_block-88           [-1, 64, 14, 14]               0\n  Inception_block-89          [-1, 512, 14, 14]               0\n           Conv2d-90          [-1, 160, 14, 14]          81,920\n      BatchNorm2d-91          [-1, 160, 14, 14]             320\n             ReLU-92          [-1, 160, 14, 14]               0\n       Conv_block-93          [-1, 160, 14, 14]               0\n           Conv2d-94          [-1, 112, 14, 14]          57,344\n      BatchNorm2d-95          [-1, 112, 14, 14]             224\n             ReLU-96          [-1, 112, 14, 14]               0\n       Conv_block-97          [-1, 112, 14, 14]               0\n           Conv2d-98          [-1, 224, 14, 14]         225,792\n      BatchNorm2d-99          [-1, 224, 14, 14]             448\n            ReLU-100          [-1, 224, 14, 14]               0\n      Conv_block-101          [-1, 224, 14, 14]               0\n          Conv2d-102           [-1, 24, 14, 14]          12,288\n     BatchNorm2d-103           [-1, 24, 14, 14]              48\n            ReLU-104           [-1, 24, 14, 14]               0\n      Conv_block-105           [-1, 24, 14, 14]               0\n          Conv2d-106           [-1, 64, 14, 14]          38,400\n     BatchNorm2d-107           [-1, 64, 14, 14]             128\n            ReLU-108           [-1, 64, 14, 14]               0\n      Conv_block-109           [-1, 64, 14, 14]               0\n       MaxPool2d-110          [-1, 512, 14, 14]               0\n          Conv2d-111           [-1, 64, 14, 14]          32,768\n     BatchNorm2d-112           [-1, 64, 14, 14]             128\n            ReLU-113           [-1, 64, 14, 14]               0\n      Conv_block-114           [-1, 64, 14, 14]               0\n Inception_block-115          [-1, 512, 14, 14]               0\n          Conv2d-116          [-1, 128, 14, 14]          65,536\n     BatchNorm2d-117          [-1, 128, 14, 14]             256\n            ReLU-118          [-1, 128, 14, 14]               0\n      Conv_block-119          [-1, 128, 14, 14]               0\n          Conv2d-120          [-1, 128, 14, 14]          65,536\n     BatchNorm2d-121          [-1, 128, 14, 14]             256\n            ReLU-122          [-1, 128, 14, 14]               0\n      Conv_block-123          [-1, 128, 14, 14]               0\n          Conv2d-124          [-1, 256, 14, 14]         294,912\n     BatchNorm2d-125          [-1, 256, 14, 14]             512\n            ReLU-126          [-1, 256, 14, 14]               0\n      Conv_block-127          [-1, 256, 14, 14]               0\n          Conv2d-128           [-1, 24, 14, 14]          12,288\n     BatchNorm2d-129           [-1, 24, 14, 14]              48\n            ReLU-130           [-1, 24, 14, 14]               0\n      Conv_block-131           [-1, 24, 14, 14]               0\n          Conv2d-132           [-1, 64, 14, 14]          38,400\n     BatchNorm2d-133           [-1, 64, 14, 14]             128\n            ReLU-134           [-1, 64, 14, 14]               0\n      Conv_block-135           [-1, 64, 14, 14]               0\n       MaxPool2d-136          [-1, 512, 14, 14]               0\n          Conv2d-137           [-1, 64, 14, 14]          32,768\n     BatchNorm2d-138           [-1, 64, 14, 14]             128\n            ReLU-139           [-1, 64, 14, 14]               0\n      Conv_block-140           [-1, 64, 14, 14]               0\n Inception_block-141          [-1, 512, 14, 14]               0\n          Conv2d-142          [-1, 112, 14, 14]          57,344\n     BatchNorm2d-143          [-1, 112, 14, 14]             224\n            ReLU-144          [-1, 112, 14, 14]               0\n      Conv_block-145          [-1, 112, 14, 14]               0\n          Conv2d-146          [-1, 144, 14, 14]          73,728\n     BatchNorm2d-147          [-1, 144, 14, 14]             288\n            ReLU-148          [-1, 144, 14, 14]               0\n      Conv_block-149          [-1, 144, 14, 14]               0\n          Conv2d-150          [-1, 288, 14, 14]         373,248\n     BatchNorm2d-151          [-1, 288, 14, 14]             576\n            ReLU-152          [-1, 288, 14, 14]               0\n      Conv_block-153          [-1, 288, 14, 14]               0\n          Conv2d-154           [-1, 32, 14, 14]          16,384\n     BatchNorm2d-155           [-1, 32, 14, 14]              64\n            ReLU-156           [-1, 32, 14, 14]               0\n      Conv_block-157           [-1, 32, 14, 14]               0\n          Conv2d-158           [-1, 64, 14, 14]          51,200\n     BatchNorm2d-159           [-1, 64, 14, 14]             128\n            ReLU-160           [-1, 64, 14, 14]               0\n      Conv_block-161           [-1, 64, 14, 14]               0\n       MaxPool2d-162          [-1, 512, 14, 14]               0\n          Conv2d-163           [-1, 64, 14, 14]          32,768\n     BatchNorm2d-164           [-1, 64, 14, 14]             128\n            ReLU-165           [-1, 64, 14, 14]               0\n      Conv_block-166           [-1, 64, 14, 14]               0\n Inception_block-167          [-1, 528, 14, 14]               0\n          Conv2d-168          [-1, 256, 14, 14]         135,168\n     BatchNorm2d-169          [-1, 256, 14, 14]             512\n            ReLU-170          [-1, 256, 14, 14]               0\n      Conv_block-171          [-1, 256, 14, 14]               0\n          Conv2d-172          [-1, 160, 14, 14]          84,480\n     BatchNorm2d-173          [-1, 160, 14, 14]             320\n            ReLU-174          [-1, 160, 14, 14]               0\n      Conv_block-175          [-1, 160, 14, 14]               0\n          Conv2d-176          [-1, 320, 14, 14]         460,800\n     BatchNorm2d-177          [-1, 320, 14, 14]             640\n            ReLU-178          [-1, 320, 14, 14]               0\n      Conv_block-179          [-1, 320, 14, 14]               0\n          Conv2d-180           [-1, 32, 14, 14]          16,896\n     BatchNorm2d-181           [-1, 32, 14, 14]              64\n            ReLU-182           [-1, 32, 14, 14]               0\n      Conv_block-183           [-1, 32, 14, 14]               0\n          Conv2d-184          [-1, 128, 14, 14]         102,400\n     BatchNorm2d-185          [-1, 128, 14, 14]             256\n            ReLU-186          [-1, 128, 14, 14]               0\n      Conv_block-187          [-1, 128, 14, 14]               0\n       MaxPool2d-188          [-1, 528, 14, 14]               0\n          Conv2d-189          [-1, 128, 14, 14]          67,584\n     BatchNorm2d-190          [-1, 128, 14, 14]             256\n            ReLU-191          [-1, 128, 14, 14]               0\n      Conv_block-192          [-1, 128, 14, 14]               0\n Inception_block-193          [-1, 832, 14, 14]               0\n       MaxPool2d-194            [-1, 832, 7, 7]               0\n          Conv2d-195            [-1, 256, 7, 7]         212,992\n     BatchNorm2d-196            [-1, 256, 7, 7]             512\n            ReLU-197            [-1, 256, 7, 7]               0\n      Conv_block-198            [-1, 256, 7, 7]               0\n          Conv2d-199            [-1, 160, 7, 7]         133,120\n     BatchNorm2d-200            [-1, 160, 7, 7]             320\n            ReLU-201            [-1, 160, 7, 7]               0\n      Conv_block-202            [-1, 160, 7, 7]               0\n          Conv2d-203            [-1, 320, 7, 7]         460,800\n     BatchNorm2d-204            [-1, 320, 7, 7]             640\n            ReLU-205            [-1, 320, 7, 7]               0\n      Conv_block-206            [-1, 320, 7, 7]               0\n          Conv2d-207             [-1, 32, 7, 7]          26,624\n     BatchNorm2d-208             [-1, 32, 7, 7]              64\n            ReLU-209             [-1, 32, 7, 7]               0\n      Conv_block-210             [-1, 32, 7, 7]               0\n          Conv2d-211            [-1, 128, 7, 7]         102,400\n     BatchNorm2d-212            [-1, 128, 7, 7]             256\n            ReLU-213            [-1, 128, 7, 7]               0\n      Conv_block-214            [-1, 128, 7, 7]               0\n       MaxPool2d-215            [-1, 832, 7, 7]               0\n          Conv2d-216            [-1, 128, 7, 7]         106,496\n     BatchNorm2d-217            [-1, 128, 7, 7]             256\n            ReLU-218            [-1, 128, 7, 7]               0\n      Conv_block-219            [-1, 128, 7, 7]               0\n Inception_block-220            [-1, 832, 7, 7]               0\n          Conv2d-221            [-1, 384, 7, 7]         319,488\n     BatchNorm2d-222            [-1, 384, 7, 7]             768\n            ReLU-223            [-1, 384, 7, 7]               0\n      Conv_block-224            [-1, 384, 7, 7]               0\n          Conv2d-225            [-1, 192, 7, 7]         159,744\n     BatchNorm2d-226            [-1, 192, 7, 7]             384\n            ReLU-227            [-1, 192, 7, 7]               0\n      Conv_block-228            [-1, 192, 7, 7]               0\n          Conv2d-229            [-1, 384, 7, 7]         663,552\n     BatchNorm2d-230            [-1, 384, 7, 7]             768\n            ReLU-231            [-1, 384, 7, 7]               0\n      Conv_block-232            [-1, 384, 7, 7]               0\n          Conv2d-233             [-1, 48, 7, 7]          39,936\n     BatchNorm2d-234             [-1, 48, 7, 7]              96\n            ReLU-235             [-1, 48, 7, 7]               0\n      Conv_block-236             [-1, 48, 7, 7]               0\n          Conv2d-237            [-1, 128, 7, 7]         153,600\n     BatchNorm2d-238            [-1, 128, 7, 7]             256\n            ReLU-239            [-1, 128, 7, 7]               0\n      Conv_block-240            [-1, 128, 7, 7]               0\n       MaxPool2d-241            [-1, 832, 7, 7]               0\n          Conv2d-242            [-1, 128, 7, 7]         106,496\n     BatchNorm2d-243            [-1, 128, 7, 7]             256\n            ReLU-244            [-1, 128, 7, 7]               0\n      Conv_block-245            [-1, 128, 7, 7]               0\n Inception_block-246           [-1, 1024, 7, 7]               0\nAdaptiveAvgPool2d-247           [-1, 1024, 1, 1]               0\n         Dropout-248           [-1, 1024, 1, 1]               0\n          Linear-249                 [-1, 1000]       1,025,000\n================================================================\nTotal params: 7,001,608\nTrainable params: 7,001,608\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 112.59\nParams size (MB): 26.71\nEstimated Total Size (MB): 139.88\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the pretrained VGG19 model\npretrained_inception = models.googlenet(pretrained=True)\nsummary(pretrained_inception, (3, 224, 224))","metadata":{"execution":{"iopub.status.busy":"2023-08-07T05:04:18.40866Z","iopub.execute_input":"2023-08-07T05:04:18.410556Z","iopub.status.idle":"2023-08-07T05:04:19.773358Z","shell.execute_reply.started":"2023-08-07T05:04:18.410492Z","shell.execute_reply":"2023-08-07T05:04:19.772252Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n100%|██████████| 49.7M/49.7M [00:00<00:00, 70.9MB/s]\n","output_type":"stream"},{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 112, 112]           9,408\n       BatchNorm2d-2         [-1, 64, 112, 112]             128\n       BasicConv2d-3         [-1, 64, 112, 112]               0\n         MaxPool2d-4           [-1, 64, 56, 56]               0\n            Conv2d-5           [-1, 64, 56, 56]           4,096\n       BatchNorm2d-6           [-1, 64, 56, 56]             128\n       BasicConv2d-7           [-1, 64, 56, 56]               0\n            Conv2d-8          [-1, 192, 56, 56]         110,592\n       BatchNorm2d-9          [-1, 192, 56, 56]             384\n      BasicConv2d-10          [-1, 192, 56, 56]               0\n        MaxPool2d-11          [-1, 192, 28, 28]               0\n           Conv2d-12           [-1, 64, 28, 28]          12,288\n      BatchNorm2d-13           [-1, 64, 28, 28]             128\n      BasicConv2d-14           [-1, 64, 28, 28]               0\n           Conv2d-15           [-1, 96, 28, 28]          18,432\n      BatchNorm2d-16           [-1, 96, 28, 28]             192\n      BasicConv2d-17           [-1, 96, 28, 28]               0\n           Conv2d-18          [-1, 128, 28, 28]         110,592\n      BatchNorm2d-19          [-1, 128, 28, 28]             256\n      BasicConv2d-20          [-1, 128, 28, 28]               0\n           Conv2d-21           [-1, 16, 28, 28]           3,072\n      BatchNorm2d-22           [-1, 16, 28, 28]              32\n      BasicConv2d-23           [-1, 16, 28, 28]               0\n           Conv2d-24           [-1, 32, 28, 28]           4,608\n      BatchNorm2d-25           [-1, 32, 28, 28]              64\n      BasicConv2d-26           [-1, 32, 28, 28]               0\n        MaxPool2d-27          [-1, 192, 28, 28]               0\n           Conv2d-28           [-1, 32, 28, 28]           6,144\n      BatchNorm2d-29           [-1, 32, 28, 28]              64\n      BasicConv2d-30           [-1, 32, 28, 28]               0\n        Inception-31          [-1, 256, 28, 28]               0\n           Conv2d-32          [-1, 128, 28, 28]          32,768\n      BatchNorm2d-33          [-1, 128, 28, 28]             256\n      BasicConv2d-34          [-1, 128, 28, 28]               0\n           Conv2d-35          [-1, 128, 28, 28]          32,768\n      BatchNorm2d-36          [-1, 128, 28, 28]             256\n      BasicConv2d-37          [-1, 128, 28, 28]               0\n           Conv2d-38          [-1, 192, 28, 28]         221,184\n      BatchNorm2d-39          [-1, 192, 28, 28]             384\n      BasicConv2d-40          [-1, 192, 28, 28]               0\n           Conv2d-41           [-1, 32, 28, 28]           8,192\n      BatchNorm2d-42           [-1, 32, 28, 28]              64\n      BasicConv2d-43           [-1, 32, 28, 28]               0\n           Conv2d-44           [-1, 96, 28, 28]          27,648\n      BatchNorm2d-45           [-1, 96, 28, 28]             192\n      BasicConv2d-46           [-1, 96, 28, 28]               0\n        MaxPool2d-47          [-1, 256, 28, 28]               0\n           Conv2d-48           [-1, 64, 28, 28]          16,384\n      BatchNorm2d-49           [-1, 64, 28, 28]             128\n      BasicConv2d-50           [-1, 64, 28, 28]               0\n        Inception-51          [-1, 480, 28, 28]               0\n        MaxPool2d-52          [-1, 480, 14, 14]               0\n           Conv2d-53          [-1, 192, 14, 14]          92,160\n      BatchNorm2d-54          [-1, 192, 14, 14]             384\n      BasicConv2d-55          [-1, 192, 14, 14]               0\n           Conv2d-56           [-1, 96, 14, 14]          46,080\n      BatchNorm2d-57           [-1, 96, 14, 14]             192\n      BasicConv2d-58           [-1, 96, 14, 14]               0\n           Conv2d-59          [-1, 208, 14, 14]         179,712\n      BatchNorm2d-60          [-1, 208, 14, 14]             416\n      BasicConv2d-61          [-1, 208, 14, 14]               0\n           Conv2d-62           [-1, 16, 14, 14]           7,680\n      BatchNorm2d-63           [-1, 16, 14, 14]              32\n      BasicConv2d-64           [-1, 16, 14, 14]               0\n           Conv2d-65           [-1, 48, 14, 14]           6,912\n      BatchNorm2d-66           [-1, 48, 14, 14]              96\n      BasicConv2d-67           [-1, 48, 14, 14]               0\n        MaxPool2d-68          [-1, 480, 14, 14]               0\n           Conv2d-69           [-1, 64, 14, 14]          30,720\n      BatchNorm2d-70           [-1, 64, 14, 14]             128\n      BasicConv2d-71           [-1, 64, 14, 14]               0\n        Inception-72          [-1, 512, 14, 14]               0\n           Conv2d-73          [-1, 160, 14, 14]          81,920\n      BatchNorm2d-74          [-1, 160, 14, 14]             320\n      BasicConv2d-75          [-1, 160, 14, 14]               0\n           Conv2d-76          [-1, 112, 14, 14]          57,344\n      BatchNorm2d-77          [-1, 112, 14, 14]             224\n      BasicConv2d-78          [-1, 112, 14, 14]               0\n           Conv2d-79          [-1, 224, 14, 14]         225,792\n      BatchNorm2d-80          [-1, 224, 14, 14]             448\n      BasicConv2d-81          [-1, 224, 14, 14]               0\n           Conv2d-82           [-1, 24, 14, 14]          12,288\n      BatchNorm2d-83           [-1, 24, 14, 14]              48\n      BasicConv2d-84           [-1, 24, 14, 14]               0\n           Conv2d-85           [-1, 64, 14, 14]          13,824\n      BatchNorm2d-86           [-1, 64, 14, 14]             128\n      BasicConv2d-87           [-1, 64, 14, 14]               0\n        MaxPool2d-88          [-1, 512, 14, 14]               0\n           Conv2d-89           [-1, 64, 14, 14]          32,768\n      BatchNorm2d-90           [-1, 64, 14, 14]             128\n      BasicConv2d-91           [-1, 64, 14, 14]               0\n        Inception-92          [-1, 512, 14, 14]               0\n           Conv2d-93          [-1, 128, 14, 14]          65,536\n      BatchNorm2d-94          [-1, 128, 14, 14]             256\n      BasicConv2d-95          [-1, 128, 14, 14]               0\n           Conv2d-96          [-1, 128, 14, 14]          65,536\n      BatchNorm2d-97          [-1, 128, 14, 14]             256\n      BasicConv2d-98          [-1, 128, 14, 14]               0\n           Conv2d-99          [-1, 256, 14, 14]         294,912\n     BatchNorm2d-100          [-1, 256, 14, 14]             512\n     BasicConv2d-101          [-1, 256, 14, 14]               0\n          Conv2d-102           [-1, 24, 14, 14]          12,288\n     BatchNorm2d-103           [-1, 24, 14, 14]              48\n     BasicConv2d-104           [-1, 24, 14, 14]               0\n          Conv2d-105           [-1, 64, 14, 14]          13,824\n     BatchNorm2d-106           [-1, 64, 14, 14]             128\n     BasicConv2d-107           [-1, 64, 14, 14]               0\n       MaxPool2d-108          [-1, 512, 14, 14]               0\n          Conv2d-109           [-1, 64, 14, 14]          32,768\n     BatchNorm2d-110           [-1, 64, 14, 14]             128\n     BasicConv2d-111           [-1, 64, 14, 14]               0\n       Inception-112          [-1, 512, 14, 14]               0\n          Conv2d-113          [-1, 112, 14, 14]          57,344\n     BatchNorm2d-114          [-1, 112, 14, 14]             224\n     BasicConv2d-115          [-1, 112, 14, 14]               0\n          Conv2d-116          [-1, 144, 14, 14]          73,728\n     BatchNorm2d-117          [-1, 144, 14, 14]             288\n     BasicConv2d-118          [-1, 144, 14, 14]               0\n          Conv2d-119          [-1, 288, 14, 14]         373,248\n     BatchNorm2d-120          [-1, 288, 14, 14]             576\n     BasicConv2d-121          [-1, 288, 14, 14]               0\n          Conv2d-122           [-1, 32, 14, 14]          16,384\n     BatchNorm2d-123           [-1, 32, 14, 14]              64\n     BasicConv2d-124           [-1, 32, 14, 14]               0\n          Conv2d-125           [-1, 64, 14, 14]          18,432\n     BatchNorm2d-126           [-1, 64, 14, 14]             128\n     BasicConv2d-127           [-1, 64, 14, 14]               0\n       MaxPool2d-128          [-1, 512, 14, 14]               0\n          Conv2d-129           [-1, 64, 14, 14]          32,768\n     BatchNorm2d-130           [-1, 64, 14, 14]             128\n     BasicConv2d-131           [-1, 64, 14, 14]               0\n       Inception-132          [-1, 528, 14, 14]               0\n          Conv2d-133          [-1, 256, 14, 14]         135,168\n     BatchNorm2d-134          [-1, 256, 14, 14]             512\n     BasicConv2d-135          [-1, 256, 14, 14]               0\n          Conv2d-136          [-1, 160, 14, 14]          84,480\n     BatchNorm2d-137          [-1, 160, 14, 14]             320\n     BasicConv2d-138          [-1, 160, 14, 14]               0\n          Conv2d-139          [-1, 320, 14, 14]         460,800\n     BatchNorm2d-140          [-1, 320, 14, 14]             640\n     BasicConv2d-141          [-1, 320, 14, 14]               0\n          Conv2d-142           [-1, 32, 14, 14]          16,896\n     BatchNorm2d-143           [-1, 32, 14, 14]              64\n     BasicConv2d-144           [-1, 32, 14, 14]               0\n          Conv2d-145          [-1, 128, 14, 14]          36,864\n     BatchNorm2d-146          [-1, 128, 14, 14]             256\n     BasicConv2d-147          [-1, 128, 14, 14]               0\n       MaxPool2d-148          [-1, 528, 14, 14]               0\n          Conv2d-149          [-1, 128, 14, 14]          67,584\n     BatchNorm2d-150          [-1, 128, 14, 14]             256\n     BasicConv2d-151          [-1, 128, 14, 14]               0\n       Inception-152          [-1, 832, 14, 14]               0\n       MaxPool2d-153            [-1, 832, 7, 7]               0\n          Conv2d-154            [-1, 256, 7, 7]         212,992\n     BatchNorm2d-155            [-1, 256, 7, 7]             512\n     BasicConv2d-156            [-1, 256, 7, 7]               0\n          Conv2d-157            [-1, 160, 7, 7]         133,120\n     BatchNorm2d-158            [-1, 160, 7, 7]             320\n     BasicConv2d-159            [-1, 160, 7, 7]               0\n          Conv2d-160            [-1, 320, 7, 7]         460,800\n     BatchNorm2d-161            [-1, 320, 7, 7]             640\n     BasicConv2d-162            [-1, 320, 7, 7]               0\n          Conv2d-163             [-1, 32, 7, 7]          26,624\n     BatchNorm2d-164             [-1, 32, 7, 7]              64\n     BasicConv2d-165             [-1, 32, 7, 7]               0\n          Conv2d-166            [-1, 128, 7, 7]          36,864\n     BatchNorm2d-167            [-1, 128, 7, 7]             256\n     BasicConv2d-168            [-1, 128, 7, 7]               0\n       MaxPool2d-169            [-1, 832, 7, 7]               0\n          Conv2d-170            [-1, 128, 7, 7]         106,496\n     BatchNorm2d-171            [-1, 128, 7, 7]             256\n     BasicConv2d-172            [-1, 128, 7, 7]               0\n       Inception-173            [-1, 832, 7, 7]               0\n          Conv2d-174            [-1, 384, 7, 7]         319,488\n     BatchNorm2d-175            [-1, 384, 7, 7]             768\n     BasicConv2d-176            [-1, 384, 7, 7]               0\n          Conv2d-177            [-1, 192, 7, 7]         159,744\n     BatchNorm2d-178            [-1, 192, 7, 7]             384\n     BasicConv2d-179            [-1, 192, 7, 7]               0\n          Conv2d-180            [-1, 384, 7, 7]         663,552\n     BatchNorm2d-181            [-1, 384, 7, 7]             768\n     BasicConv2d-182            [-1, 384, 7, 7]               0\n          Conv2d-183             [-1, 48, 7, 7]          39,936\n     BatchNorm2d-184             [-1, 48, 7, 7]              96\n     BasicConv2d-185             [-1, 48, 7, 7]               0\n          Conv2d-186            [-1, 128, 7, 7]          55,296\n     BatchNorm2d-187            [-1, 128, 7, 7]             256\n     BasicConv2d-188            [-1, 128, 7, 7]               0\n       MaxPool2d-189            [-1, 832, 7, 7]               0\n          Conv2d-190            [-1, 128, 7, 7]         106,496\n     BatchNorm2d-191            [-1, 128, 7, 7]             256\n     BasicConv2d-192            [-1, 128, 7, 7]               0\n       Inception-193           [-1, 1024, 7, 7]               0\nAdaptiveAvgPool2d-194           [-1, 1024, 1, 1]               0\n         Dropout-195                 [-1, 1024]               0\n          Linear-196                 [-1, 1000]       1,025,000\n================================================================\nTotal params: 6,624,904\nTrainable params: 6,624,904\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 94.11\nParams size (MB): 25.27\nEstimated Total Size (MB): 119.95\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}